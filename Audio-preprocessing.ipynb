{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "616141f6-54e2-436f-9804-54a984c31595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7864\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7864/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def greet(name, intensity):\n",
    "    return \"Hello, \" + name + \"!\" * int(intensity)\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn=greet,\n",
    "    inputs=[\"text\", \"slider\"],\n",
    "    outputs=[\"text\"],\n",
    ")\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00b2ff83-8d35-4e3d-986e-6da3df0b7caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7863\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 8\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHello \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m demo \u001b[38;5;241m=\u001b[39m gr\u001b[38;5;241m.\u001b[39mInterface(fn\u001b[38;5;241m=\u001b[39mgreet, inputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtextbox\u001b[39m\u001b[38;5;124m\"\u001b[39m, outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtextbox\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m \u001b[43mdemo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlaunch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshare\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Share your demo with just 1 extra parameter ðŸš€\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.8/lib/python3.10/site-packages/gradio/blocks.py:2608\u001b[0m, in \u001b[0;36mBlocks.launch\u001b[0;34m(self, inline, inbrowser, share, debug, max_threads, auth, auth_message, prevent_thread_lock, show_error, server_name, server_port, height, width, favicon_path, ssl_keyfile, ssl_certfile, ssl_keyfile_password, ssl_verify, quiet, show_api, allowed_paths, blocked_paths, root_path, app_kwargs, state_session_capacity, share_server_address, share_server_protocol, auth_dependency, max_file_size, enable_monitoring, strict_cors, node_server_name, node_port, ssr_mode, _frontend)\u001b[0m\n\u001b[1;32m   2606\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2607\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshare_url \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 2608\u001b[0m         share_url \u001b[38;5;241m=\u001b[39m \u001b[43mnetworking\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup_tunnel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2609\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlocal_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserver_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2610\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlocal_port\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserver_port\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2611\u001b[0m \u001b[43m            \u001b[49m\u001b[43mshare_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshare_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2612\u001b[0m \u001b[43m            \u001b[49m\u001b[43mshare_server_address\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshare_server_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2613\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2614\u001b[0m         parsed_url \u001b[38;5;241m=\u001b[39m urlparse(share_url)\n\u001b[1;32m   2615\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshare_url \u001b[38;5;241m=\u001b[39m urlunparse(\n\u001b[1;32m   2616\u001b[0m             (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshare_server_protocol,) \u001b[38;5;241m+\u001b[39m parsed_url[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m   2617\u001b[0m         )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.8/lib/python3.10/site-packages/gradio/networking.py:47\u001b[0m, in \u001b[0;36msetup_tunnel\u001b[0;34m(local_host, local_port, share_token, share_server_address)\u001b[0m\n\u001b[1;32m     45\u001b[0m     remote_port \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(remote_port)\n\u001b[1;32m     46\u001b[0m tunnel \u001b[38;5;241m=\u001b[39m Tunnel(remote_host, remote_port, local_host, local_port, share_token)\n\u001b[0;32m---> 47\u001b[0m address \u001b[38;5;241m=\u001b[39m \u001b[43mtunnel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_tunnel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m address\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.8/lib/python3.10/site-packages/gradio/tunneling.py:103\u001b[0m, in \u001b[0;36mTunnel.start_tunnel\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstart_tunnel\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownload_binary()\n\u001b[0;32m--> 103\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_start_tunnel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBINARY_PATH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.8/lib/python3.10/site-packages/gradio/tunneling.py:138\u001b[0m, in \u001b[0;36mTunnel._start_tunnel\u001b[0;34m(self, binary)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproc \u001b[38;5;241m=\u001b[39m subprocess\u001b[38;5;241m.\u001b[39mPopen(\n\u001b[1;32m    135\u001b[0m     command, stdout\u001b[38;5;241m=\u001b[39msubprocess\u001b[38;5;241m.\u001b[39mPIPE, stderr\u001b[38;5;241m=\u001b[39msubprocess\u001b[38;5;241m.\u001b[39mPIPE\n\u001b[1;32m    136\u001b[0m )\n\u001b[1;32m    137\u001b[0m atexit\u001b[38;5;241m.\u001b[39mregister(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkill)\n\u001b[0;32m--> 138\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_url_from_tunnel_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.8/lib/python3.10/site-packages/gradio/tunneling.py:160\u001b[0m, in \u001b[0;36mTunnel._read_url_from_tunnel_stream\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproc\u001b[38;5;241m.\u001b[39mstdout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m--> 160\u001b[0m line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstdout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m line \u001b[38;5;241m=\u001b[39m line\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m line \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def greet(name):\n",
    "    return \"Hello \" + name + \"!\"\n",
    "\n",
    "demo = gr.Interface(fn=greet, inputs=\"textbox\", outputs=\"textbox\")\n",
    "    \n",
    "demo.launch(share=True)  # Share your demo with just 1 extra parameter ðŸš€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32d815a0-5fca-41a9-9ae2-27bb184f9cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7868\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7868/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/nathalia/.pyenv/versions/3.10.8/lib/python3.10/site-packages/gradio/queueing.py\", line 622, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "  File \"/Users/nathalia/.pyenv/versions/3.10.8/lib/python3.10/site-packages/gradio/route_utils.py\", line 323, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"/Users/nathalia/.pyenv/versions/3.10.8/lib/python3.10/site-packages/gradio/blocks.py\", line 2014, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"/Users/nathalia/.pyenv/versions/3.10.8/lib/python3.10/site-packages/gradio/blocks.py\", line 1567, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
      "  File \"/Users/nathalia/.pyenv/versions/3.10.8/lib/python3.10/site-packages/anyio/to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "  File \"/Users/nathalia/.pyenv/versions/3.10.8/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 2441, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"/Users/nathalia/.pyenv/versions/3.10.8/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 943, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"/Users/nathalia/.pyenv/versions/3.10.8/lib/python3.10/site-packages/gradio/utils.py\", line 846, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"/var/folders/fk/fbj1ksls7wq3z6dyxsdrrz9w0000gn/T/ipykernel_72498/595921842.py\", line 8, in transcribe\n",
      "    sr, y = audio\n",
      "TypeError: cannot unpack non-iterable NoneType object\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nathalia/.pyenv/versions/3.10.8/lib/python3.10/site-packages/gradio/queueing.py\", line 622, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "  File \"/Users/nathalia/.pyenv/versions/3.10.8/lib/python3.10/site-packages/gradio/route_utils.py\", line 323, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"/Users/nathalia/.pyenv/versions/3.10.8/lib/python3.10/site-packages/gradio/blocks.py\", line 2014, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"/Users/nathalia/.pyenv/versions/3.10.8/lib/python3.10/site-packages/gradio/blocks.py\", line 1567, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
      "  File \"/Users/nathalia/.pyenv/versions/3.10.8/lib/python3.10/site-packages/anyio/to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "  File \"/Users/nathalia/.pyenv/versions/3.10.8/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 2441, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"/Users/nathalia/.pyenv/versions/3.10.8/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 943, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"/Users/nathalia/.pyenv/versions/3.10.8/lib/python3.10/site-packages/gradio/utils.py\", line 846, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"/var/folders/fk/fbj1ksls7wq3z6dyxsdrrz9w0000gn/T/ipykernel_72498/595921842.py\", line 8, in transcribe\n",
      "    sr, y = audio\n",
      "TypeError: cannot unpack non-iterable NoneType object\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nathalia/.pyenv/versions/3.10.8/lib/python3.10/site-packages/gradio/queueing.py\", line 622, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "  File \"/Users/nathalia/.pyenv/versions/3.10.8/lib/python3.10/site-packages/gradio/route_utils.py\", line 323, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"/Users/nathalia/.pyenv/versions/3.10.8/lib/python3.10/site-packages/gradio/blocks.py\", line 2014, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"/Users/nathalia/.pyenv/versions/3.10.8/lib/python3.10/site-packages/gradio/blocks.py\", line 1567, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
      "  File \"/Users/nathalia/.pyenv/versions/3.10.8/lib/python3.10/site-packages/anyio/to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "  File \"/Users/nathalia/.pyenv/versions/3.10.8/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 2441, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"/Users/nathalia/.pyenv/versions/3.10.8/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 943, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"/Users/nathalia/.pyenv/versions/3.10.8/lib/python3.10/site-packages/gradio/utils.py\", line 846, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"/var/folders/fk/fbj1ksls7wq3z6dyxsdrrz9w0000gn/T/ipykernel_72498/595921842.py\", line 8, in transcribe\n",
      "    sr, y = audio\n",
      "TypeError: cannot unpack non-iterable NoneType object\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nathalia/.pyenv/versions/3.10.8/lib/python3.10/site-packages/gradio/queueing.py\", line 622, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "  File \"/Users/nathalia/.pyenv/versions/3.10.8/lib/python3.10/site-packages/gradio/route_utils.py\", line 323, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"/Users/nathalia/.pyenv/versions/3.10.8/lib/python3.10/site-packages/gradio/blocks.py\", line 2014, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"/Users/nathalia/.pyenv/versions/3.10.8/lib/python3.10/site-packages/gradio/blocks.py\", line 1567, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
      "  File \"/Users/nathalia/.pyenv/versions/3.10.8/lib/python3.10/site-packages/anyio/to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "  File \"/Users/nathalia/.pyenv/versions/3.10.8/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 2441, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"/Users/nathalia/.pyenv/versions/3.10.8/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 943, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"/Users/nathalia/.pyenv/versions/3.10.8/lib/python3.10/site-packages/gradio/utils.py\", line 846, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"/var/folders/fk/fbj1ksls7wq3z6dyxsdrrz9w0000gn/T/ipykernel_72498/595921842.py\", line 8, in transcribe\n",
      "    sr, y = audio\n",
      "TypeError: cannot unpack non-iterable NoneType object\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nathalia/.pyenv/versions/3.10.8/lib/python3.10/site-packages/gradio/queueing.py\", line 622, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "  File \"/Users/nathalia/.pyenv/versions/3.10.8/lib/python3.10/site-packages/gradio/route_utils.py\", line 323, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"/Users/nathalia/.pyenv/versions/3.10.8/lib/python3.10/site-packages/gradio/blocks.py\", line 2014, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"/Users/nathalia/.pyenv/versions/3.10.8/lib/python3.10/site-packages/gradio/blocks.py\", line 1567, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
      "  File \"/Users/nathalia/.pyenv/versions/3.10.8/lib/python3.10/site-packages/anyio/to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "  File \"/Users/nathalia/.pyenv/versions/3.10.8/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 2441, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"/Users/nathalia/.pyenv/versions/3.10.8/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 943, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"/Users/nathalia/.pyenv/versions/3.10.8/lib/python3.10/site-packages/gradio/utils.py\", line 846, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"/var/folders/fk/fbj1ksls7wq3z6dyxsdrrz9w0000gn/T/ipykernel_72498/595921842.py\", line 8, in transcribe\n",
      "    sr, y = audio\n",
      "TypeError: cannot unpack non-iterable NoneType object\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from transformers import pipeline\n",
    "import numpy as np\n",
    "\n",
    "transcriber = pipeline(\"automatic-speech-recognition\", model=\"openai/whisper-base.en\")\n",
    "\n",
    "def transcribe(audio):\n",
    "    sr, y = audio\n",
    "    \n",
    "    # Convert to mono if stereo\n",
    "    if y.ndim > 1:\n",
    "        y = y.mean(axis=1)\n",
    "        \n",
    "    y = y.astype(np.float32)\n",
    "    y /= np.max(np.abs(y))\n",
    "\n",
    "    return transcriber({\"sampling_rate\": sr, \"raw\": y})[\"text\"]  \n",
    "\n",
    "demo = gr.Interface(\n",
    "    transcribe,\n",
    "    gr.Audio(sources=\"microphone\"),\n",
    "    \"text\",\n",
    ")\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70abf02f-b6c5-4b98-aace-0a0e3802841d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7867\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7867/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from transformers import pipeline\n",
    "import numpy as np\n",
    "\n",
    "transcriber = pipeline(\"automatic-speech-recognition\", model=\"openai/whisper-base.en\")\n",
    "\n",
    "def transcribe(stream, new_chunk):\n",
    "    sr, y = new_chunk\n",
    "    \n",
    "    # Convert to mono if stereo\n",
    "    if y.ndim > 1:\n",
    "        y = y.mean(axis=1)\n",
    "        \n",
    "    y = y.astype(np.float32)\n",
    "    y /= np.max(np.abs(y))\n",
    "\n",
    "    if stream is not None:\n",
    "        stream = np.concatenate([stream, y])\n",
    "    else:\n",
    "        stream = y\n",
    "    return stream, transcriber({\"sampling_rate\": sr, \"raw\": stream})[\"text\"]  \n",
    "\n",
    "demo = gr.Interface(\n",
    "    transcribe,\n",
    "    [\"state\", gr.Audio(sources=[\"microphone\"], streaming=True)],\n",
    "    [\"state\", \"text\"],\n",
    "    live=True,\n",
    ")\n",
    "\n",
    "demo.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a1a4c0-40c4-47cb-9ada-88778188c224",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
