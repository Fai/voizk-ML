{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b31344e-76b0-49cc-b41b-3ee5893a02b4",
   "metadata": {},
   "source": [
    "## Exploring ONNX Export Optimization and Model Preprocessing for RawNet3 Integration with ezkl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17089d36-6b48-4961-b6e5-4b5edba2bc6e",
   "metadata": {},
   "source": [
    "In this notebook, we explore techniques to optimize the ONNX export configuration and preprocess the exported ONNX model to address the compatibility issues encountered when integrating the RawNet3 model with ezkl for speaker verification using zero-knowledge proofs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abc9d85-74ef-463c-9a87-93af3ed53642",
   "metadata": {},
   "source": [
    "### Importing Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e36f5adf-fa91-4bbc-b28e-68c12fb7d046",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import json\n",
    "import ezkl\n",
    "import librosa\n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from asteroid_filterbanks import Encoder, ParamSincFB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8496a1-6c2f-45b0-a9ec-cf12fbfe6fa4",
   "metadata": {},
   "source": [
    "### Defining RawNet3 Model Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2f373b93-e4a2-444b-97fb-5699da36e864",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreEmphasis(torch.nn.Module):\n",
    "    def __init__(self, coef: float = 0.97) -> None:\n",
    "        super().__init__()\n",
    "        self.coef = coef\n",
    "        self.register_buffer(\n",
    "            \"flipped_filter\",\n",
    "            torch.FloatTensor([-self.coef, 1.0]).unsqueeze(0).unsqueeze(0),\n",
    "        )\n",
    "\n",
    "    def forward(self, input: torch.tensor) -> torch.tensor:\n",
    "        assert (\n",
    "            len(input.size()) == 2\n",
    "        ), \"The number of dimensions of input tensor must be 2!\"\n",
    "        input = input.unsqueeze(1)\n",
    "        input = F.pad(input, (1, 0), \"reflect\")\n",
    "        return F.conv1d(input, self.flipped_filter)\n",
    "\n",
    "class AFMS(nn.Module):\n",
    "    def __init__(self, nb_dim: int) -> None:\n",
    "        super().__init__()\n",
    "        self.alpha = nn.Parameter(torch.ones((nb_dim, 1)))\n",
    "        self.fc = nn.Linear(nb_dim, nb_dim)\n",
    "        self.sig = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = F.adaptive_avg_pool1d(x, 1).view(x.size(0), -1)\n",
    "        y = self.sig(self.fc(y)).view(x.size(0), x.size(1), -1)\n",
    "\n",
    "        x = x + self.alpha\n",
    "        x = x * y\n",
    "        return x\n",
    "\n",
    "class Bottle2neck(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        inplanes,\n",
    "        planes,\n",
    "        kernel_size=None,\n",
    "        dilation=None,\n",
    "        scale=4,\n",
    "        pool=False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        width = int(math.floor(planes / scale))\n",
    "        self.conv1 = nn.Conv1d(inplanes, width * scale, kernel_size=1)\n",
    "        self.bn1 = nn.BatchNorm1d(width * scale)\n",
    "        self.nums = scale - 1\n",
    "        convs = []\n",
    "        bns = []\n",
    "        num_pad = math.floor(kernel_size / 2) * dilation\n",
    "        for i in range(self.nums):\n",
    "            convs.append(\n",
    "                nn.Conv1d(\n",
    "                    width,\n",
    "                    width,\n",
    "                    kernel_size=kernel_size,\n",
    "                    dilation=dilation,\n",
    "                    padding=num_pad,\n",
    "                )\n",
    "            )\n",
    "            bns.append(nn.BatchNorm1d(width))\n",
    "        self.convs = nn.ModuleList(convs)\n",
    "        self.bns = nn.ModuleList(bns)\n",
    "        self.conv3 = nn.Conv1d(width * scale, planes, kernel_size=1)\n",
    "        self.bn3 = nn.BatchNorm1d(planes)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.width = width\n",
    "        self.mp = nn.MaxPool1d(pool) if pool else False\n",
    "        self.afms = AFMS(planes)\n",
    "        if inplanes != planes:\n",
    "            self.residual = nn.Sequential(\n",
    "                nn.Conv1d(inplanes, planes, kernel_size=1, stride=1, bias=False)\n",
    "            )\n",
    "        else:\n",
    "            self.residual = nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = self.residual(x)\n",
    "        out = self.conv1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.bn1(out)\n",
    "        spx = torch.split(out, self.width, 1)\n",
    "        for i in range(self.nums):\n",
    "            if i == 0:\n",
    "                sp = spx[i]\n",
    "            else:\n",
    "                sp = sp + spx[i]\n",
    "            sp = self.convs[i](sp)\n",
    "            sp = self.relu(sp)\n",
    "            sp = self.bns[i](sp)\n",
    "            if i == 0:\n",
    "                out = sp\n",
    "            else:\n",
    "                out = torch.cat((out, sp), 1)\n",
    "        out = torch.cat((out, spx[self.nums]), 1)\n",
    "        out = self.conv3(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.bn3(out)\n",
    "        out += residual\n",
    "        if self.mp:\n",
    "            out = self.mp(out)\n",
    "        out = self.afms(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "00b3cee9-ee35-4a47-895a-10ab3f2206a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RawNet3.py\n",
    "class RawNet3(nn.Module):\n",
    "    def __init__(self, block, model_scale, context, summed, C=1024, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        nOut = kwargs[\"nOut\"]\n",
    "\n",
    "        self.context = context\n",
    "        self.encoder_type = kwargs[\"encoder_type\"]\n",
    "        self.log_sinc = kwargs[\"log_sinc\"]\n",
    "        self.norm_sinc = kwargs[\"norm_sinc\"]\n",
    "        self.out_bn = kwargs[\"out_bn\"]\n",
    "        self.summed = summed\n",
    "\n",
    "        self.preprocess = nn.Sequential(\n",
    "            PreEmphasis(), nn.InstanceNorm1d(1, eps=1e-4, affine=True)\n",
    "        )\n",
    "        self.conv1 = Encoder(\n",
    "            ParamSincFB(\n",
    "                C // 4,\n",
    "                251,\n",
    "                stride=kwargs[\"sinc_stride\"],\n",
    "            )\n",
    "        )\n",
    "        self.relu = nn.ReLU()\n",
    "        self.bn1 = nn.BatchNorm1d(C // 4)\n",
    "\n",
    "        self.layer1 = block(\n",
    "            C // 4, C, kernel_size=3, dilation=2, scale=model_scale, pool=5\n",
    "        )\n",
    "        self.layer2 = block(\n",
    "            C, C, kernel_size=3, dilation=3, scale=model_scale, pool=3\n",
    "        )\n",
    "        self.layer3 = block(C, C, kernel_size=3, dilation=4, scale=model_scale)\n",
    "        self.layer4 = nn.Conv1d(3 * C, 1536, kernel_size=1)\n",
    "\n",
    "        if self.context:\n",
    "            attn_input = 1536 * 3\n",
    "        else:\n",
    "            attn_input = 1536\n",
    "        print(\"self.encoder_type\", self.encoder_type)\n",
    "        if self.encoder_type == \"ECA\":\n",
    "            attn_output = 1536\n",
    "        elif self.encoder_type == \"ASP\":\n",
    "            attn_output = 1\n",
    "        else:\n",
    "            raise ValueError(\"Undefined encoder\")\n",
    "\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Conv1d(attn_input, 128, kernel_size=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Conv1d(128, attn_output, kernel_size=1),\n",
    "            nn.Softmax(dim=2),\n",
    "        )\n",
    "\n",
    "        self.bn5 = nn.BatchNorm1d(3072)\n",
    "\n",
    "        self.fc6 = nn.Linear(3072, nOut)\n",
    "        self.bn6 = nn.BatchNorm1d(nOut)\n",
    "\n",
    "        self.mp3 = nn.MaxPool1d(3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        :param x: input mini-batch (bs, samp)\n",
    "        \"\"\"\n",
    "\n",
    "        with torch.cuda.amp.autocast(enabled=False):\n",
    "            x = self.preprocess(x)\n",
    "            x = torch.abs(self.conv1(x))\n",
    "            if self.log_sinc:\n",
    "                x = torch.log(x + 1e-6)\n",
    "            if self.norm_sinc == \"mean\":\n",
    "                x = x - torch.mean(x, dim=-1, keepdim=True)\n",
    "            elif self.norm_sinc == \"mean_std\":\n",
    "                m = torch.mean(x, dim=-1, keepdim=True)\n",
    "                s = torch.std(x, dim=-1, keepdim=True)\n",
    "                s[s < 0.001] = 0.001\n",
    "                x = (x - m) / s\n",
    "\n",
    "        if self.summed:\n",
    "            x1 = self.layer1(x)\n",
    "            x2 = self.layer2(x1)\n",
    "            x3 = self.layer3(self.mp3(x1) + x2)\n",
    "        else:\n",
    "            x1 = self.layer1(x)\n",
    "            x2 = self.layer2(x1)\n",
    "            x3 = self.layer3(x2)\n",
    "\n",
    "        x = self.layer4(torch.cat((self.mp3(x1), x2, x3), dim=1))\n",
    "        x = self.relu(x)\n",
    "\n",
    "        t = x.size()[-1]\n",
    "\n",
    "        if self.context:\n",
    "            global_x = torch.cat(\n",
    "                (\n",
    "                    x,\n",
    "                    torch.mean(x, dim=2, keepdim=True).repeat(1, 1, t),\n",
    "                    torch.sqrt(\n",
    "                        torch.var(x, dim=2, keepdim=True).clamp(\n",
    "                            min=1e-4, max=1e4\n",
    "                        )\n",
    "                    ).repeat(1, 1, t),\n",
    "                ),\n",
    "                dim=1,\n",
    "            )\n",
    "        else:\n",
    "            global_x = x\n",
    "\n",
    "        w = self.attention(global_x)\n",
    "\n",
    "        mu = torch.sum(x * w, dim=2)\n",
    "        sg = torch.sqrt(\n",
    "            (torch.sum((x**2) * w, dim=2) - mu**2).clamp(min=1e-4, max=1e4)\n",
    "        )\n",
    "\n",
    "        x = torch.cat((mu, sg), 1)\n",
    "\n",
    "        x = self.bn5(x)\n",
    "\n",
    "        x = self.fc6(x)\n",
    "\n",
    "        if self.out_bn:\n",
    "            x = self.bn6(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "59fe3a3e-f304-4146-a77e-9a5049231306",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MainModel(**kwargs):\n",
    "\n",
    "    model = RawNet3(\n",
    "        Bottle2neck, model_scale=8, context=True, summed=True, **kwargs\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10322d9a-7cb6-45e1-ba54-d57bc091613b",
   "metadata": {},
   "source": [
    "### Loading the Pre-trained RawNet3 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f1288e8c-7b26-463e-b62d-511b2928a1a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.encoder_type ECA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fk/fbj1ksls7wq3z6dyxsdrrz9w0000gn/T/ipykernel_3217/3791338880.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"./models/model.pt\", map_location=lambda storage, loc: storage)[\"model\"])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RawNet3(\n",
       "  (preprocess): Sequential(\n",
       "    (0): PreEmphasis()\n",
       "    (1): InstanceNorm1d(1, eps=0.0001, momentum=0.1, affine=True, track_running_stats=False)\n",
       "  )\n",
       "  (conv1): Encoder(\n",
       "    (filterbank): ParamSincFB()\n",
       "  )\n",
       "  (relu): ReLU()\n",
       "  (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layer1): Bottle2neck(\n",
       "    (conv1): Conv1d(256, 1024, kernel_size=(1,), stride=(1,))\n",
       "    (bn1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (convs): ModuleList(\n",
       "      (0-6): 7 x Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "    )\n",
       "    (bns): ModuleList(\n",
       "      (0-6): 7 x BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv3): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))\n",
       "    (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "    (mp): MaxPool1d(kernel_size=5, stride=5, padding=0, dilation=1, ceil_mode=False)\n",
       "    (afms): AFMS(\n",
       "      (fc): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (sig): Sigmoid()\n",
       "    )\n",
       "    (residual): Sequential(\n",
       "      (0): Conv1d(256, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Bottle2neck(\n",
       "    (conv1): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))\n",
       "    (bn1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (convs): ModuleList(\n",
       "      (0-6): 7 x Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))\n",
       "    )\n",
       "    (bns): ModuleList(\n",
       "      (0-6): 7 x BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv3): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))\n",
       "    (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "    (mp): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "    (afms): AFMS(\n",
       "      (fc): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (sig): Sigmoid()\n",
       "    )\n",
       "    (residual): Identity()\n",
       "  )\n",
       "  (layer3): Bottle2neck(\n",
       "    (conv1): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))\n",
       "    (bn1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (convs): ModuleList(\n",
       "      (0-6): 7 x Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))\n",
       "    )\n",
       "    (bns): ModuleList(\n",
       "      (0-6): 7 x BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv3): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))\n",
       "    (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "    (afms): AFMS(\n",
       "      (fc): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (sig): Sigmoid()\n",
       "    )\n",
       "    (residual): Identity()\n",
       "  )\n",
       "  (layer4): Conv1d(3072, 1536, kernel_size=(1,), stride=(1,))\n",
       "  (attention): Sequential(\n",
       "    (0): Conv1d(4608, 128, kernel_size=(1,), stride=(1,))\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Conv1d(128, 1536, kernel_size=(1,), stride=(1,))\n",
       "    (4): Softmax(dim=2)\n",
       "  )\n",
       "  (bn5): BatchNorm1d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc6): Linear(in_features=3072, out_features=256, bias=True)\n",
       "  (bn6): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (mp3): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MainModel(nOut=256, encoder_type=\"ECA\", log_sinc=True, norm_sinc=\"mean\", out_bn=False, sinc_stride=10)\n",
    "model.load_state_dict(torch.load(\"./models/model.pt\", map_location=lambda storage, loc: storage)[\"model\"])\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84df36c-649f-4973-a7eb-508e0ad90c8e",
   "metadata": {},
   "source": [
    "## Integration with ezkl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae5076c-9b2e-4eb3-92b2-3be212b41ef7",
   "metadata": {},
   "source": [
    "### Exporting the Model to ONNX \n",
    "\n",
    "Here, we export the RawNet3 model to the ONNX format using torch.onnx.export(). \n",
    "\n",
    "We specify the model, input tensor, output file path, and other export configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ddde7172-3d92-45e6-bda2-2020ffdcc280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load an audio file for testing\n",
    "audio_file = \"./sample1.wav\"\n",
    "audio, sample_rate = librosa.load(audio_file, sr=16000, mono=True)\n",
    "audio = audio[:48000]  # Truncate to 3 seconds (48000 samples)\n",
    "audio_tensor = torch.from_numpy(audio).float().unsqueeze(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "13b9a1c4-30c1-4113-87c2-0368bbfecdc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fk/fbj1ksls7wq3z6dyxsdrrz9w0000gn/T/ipykernel_3217/1709252647.py:69: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n"
     ]
    }
   ],
   "source": [
    "# Exporta el modelo a ONNX\n",
    "torch.onnx.export(model,                     # modelo a ejecutar\n",
    "                  audio_tensor,              # entrada del modelo\n",
    "                  'network.onnx',            # donde guardar el modelo\n",
    "                  export_params=True,        # almacenar los pesos entrenados dentro del archivo del modelo\n",
    "                  opset_version=10,          # la versión de ONNX a la que exportar el modelo\n",
    "                  do_constant_folding=True,  # si ejecutar constant folding para optimización\n",
    "                  input_names = ['input'],   # nombres de entrada del modelo\n",
    "                  output_names = ['output'], # nombres de salida del modelo\n",
    "                  dynamic_axes={'input' : {0 : 'batch_size'},    # ejes de longitud variable\n",
    "                                'output' : {0 : 'batch_size'}})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ecf0eeb-de54-44c2-9e01-bd57a85ad182",
   "metadata": {},
   "source": [
    "### Optimizing the ONNX Model using ONNX Optimizer\n",
    "\n",
    "We use the ONNX Optimizer to optimize the exported ONNX model. \n",
    "\n",
    "We load the ONNX model, apply a series of optimization passes using onnxoptimizer.optimize(), and save the optimized model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "efa0fad0-e41d-4361-8989-238af28cf1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize the ONNX model using ONNX Optimizer\n",
    "import onnx\n",
    "from onnxoptimizer import optimize\n",
    "\n",
    "# Load the ONNX model\n",
    "model = onnx.load('network.onnx')\n",
    "\n",
    "# Apply optimizations to the ONNX model\n",
    "optimized_model = optimize(model)\n",
    "\n",
    "# Save the optimized ONNX model\n",
    "onnx.save(optimized_model, 'network_optimized.onnx')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926a4455-357d-4acc-9271-aef4e0e171a5",
   "metadata": {},
   "source": [
    "### Specifying Files and Paths\n",
    "\n",
    "We specify the paths for the optimized ONNX model, input data, and calibration data files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3550ebcf-14ad-4b1b-9053-c471f5597ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.join('network_optimized.onnx')\n",
    "data_path = os.path.join('input.json')\n",
    "cal_data_path = os.path.join('calibration.json')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef77bce2-2dad-4420-80ef-b7f1bc1ba976",
   "metadata": {},
   "source": [
    "### Generating ezkl Settings\n",
    "\n",
    "In this code block, we attempt to generate the ezkl settings using the optimized ONNX model by calling ezkl.gen_settings()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "48028388-3bbc-4a84-87c9-d1291fc5e593",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Failed to generate settings: [graph] [tract] Translating node #71 \"If_109\" If ToTypedTranslator",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Generate ezkl settings using the optimized ONNX model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mezkl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen_settings\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m res \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to generate settings: [graph] [tract] Translating node #71 \"If_109\" If ToTypedTranslator"
     ]
    }
   ],
   "source": [
    "# Generate ezkl settings using the optimized ONNX model\n",
    "res = ezkl.gen_settings()\n",
    "assert res == True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42bbb5f4-b16f-4286-bd56-1578d7a12484",
   "metadata": {},
   "source": [
    "### Error Explanation: \n",
    "\n",
    "This error suggests that ezkl has limitations in handling conditional statements and control flow operations present in the RawNet3 model.\n",
    "\n",
    "#### Implications and Limitations: \n",
    "\n",
    "The encountered error highlights the limitations of ezkl in supporting complex operations and control flow structures commonly found in neural network models like RawNet3. Despite the attempts to optimize the ONNX export configuration and preprocess the model using ONNX Optimizer, the compatibility issues persist.\n",
    "\n",
    "ezkl is primarily designed for zero-knowledge proofs and may not have full support for the diverse range of operations and architectures used in deep learning models. Conditional statements, such as the \"If\" node, pose challenges for ezkl's type translator, making it difficult to convert the model into a format suitable for zero-knowledge proofs.\n",
    "\n",
    "The complexity of the RawNet3 model, with its various layers and operations, further compounds the compatibility issues. The presence of unsupported operations and control flow structures in the model architecture makes it challenging to integrate with ezkl seamlessly.\n",
    "\n",
    "#### Conclusion: \n",
    "\n",
    "Despite the efforts to optimize the ONNX export configuration and preprocess the RawNet3 model using ONNX Optimizer, the integration with ezkl remains unsuccessful due to the limitations of ezkl in handling complex operations and control flow structures present in the model.\n",
    "\n",
    "The encountered error underscores the challenges in integrating deep learning models like RawNet3 with zero-knowledge proof frameworks like ezkl. The incompatibility arises from the fundamental differences in the supported operations and the complexity of the model architecture.\n",
    "\n",
    "Integrating RawNet3 and similar neural network models with ezkl would require significant modifications to the model architecture, potentially simplifying or removing unsupported operations. However, such modifications may impact the model's performance and functionality.\n",
    "\n",
    "Further research and development efforts are needed to bridge the gap between complex deep learning models and zero-knowledge proof frameworks. This may involve enhancing ezkl's capabilities to support a wider range of operations or exploring alternative approaches that can accommodate the intricacies of models like RawNet3.\n",
    "\n",
    "In conclusion, the integration of RawNet3 with ezkl using ONNX export optimization and model preprocessing techniques remains a complex challenge due to the limitations of ezkl in handling the model's conditional statements and control flow operations. Addressing this compatibility issue requires further investigation, collaboration with the ezkl development team, and potential advancements in zero-knowledge proof frameworks to support complex neural network models effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e05ce39-e00b-4275-ad38-42418a7771df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
