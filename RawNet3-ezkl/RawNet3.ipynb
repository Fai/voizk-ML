{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9d284b2-0f97-4ce0-a410-936cddd7061f",
   "metadata": {},
   "source": [
    "### RawNetBasicBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "630b1ff5-1d42-48a9-87e3-9b59e2d3093f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from asteroid_filterbanks import Encoder, ParamSincFB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "30320a5a-6dd5-4e4b-808d-12f4bd530948",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class PreEmphasis(torch.nn.Module):\n",
    "    def __init__(self, coef: float = 0.97) -> None:\n",
    "        super().__init__()\n",
    "        self.coef = coef\n",
    "        self.register_buffer(\n",
    "            \"flipped_filter\",\n",
    "            torch.FloatTensor([-self.coef, 1.0]).unsqueeze(0).unsqueeze(0),\n",
    "        )\n",
    "\n",
    "    def forward(self, input: torch.tensor) -> torch.tensor:\n",
    "        assert (\n",
    "            len(input.size()) == 2\n",
    "        ), \"The number of dimensions of input tensor must be 2!\"\n",
    "        input = input.unsqueeze(1)\n",
    "        input = F.pad(input, (1, 0), \"reflect\")\n",
    "        return F.conv1d(input, self.flipped_filter)\n",
    "\n",
    "class AFMS(nn.Module):\n",
    "    def __init__(self, nb_dim: int) -> None:\n",
    "        super().__init__()\n",
    "        self.alpha = nn.Parameter(torch.ones((nb_dim, 1)))\n",
    "        self.fc = nn.Linear(nb_dim, nb_dim)\n",
    "        self.sig = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = F.adaptive_avg_pool1d(x, 1).view(x.size(0), -1)\n",
    "        y = self.sig(self.fc(y)).view(x.size(0), x.size(1), -1)\n",
    "\n",
    "        x = x + self.alpha\n",
    "        x = x * y\n",
    "        return x\n",
    "\n",
    "class Bottle2neck(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        inplanes,\n",
    "        planes,\n",
    "        kernel_size=None,\n",
    "        dilation=None,\n",
    "        scale=4,\n",
    "        pool=False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        width = int(math.floor(planes / scale))\n",
    "        self.conv1 = nn.Conv1d(inplanes, width * scale, kernel_size=1)\n",
    "        self.bn1 = nn.BatchNorm1d(width * scale)\n",
    "        self.nums = scale - 1\n",
    "        convs = []\n",
    "        bns = []\n",
    "        num_pad = math.floor(kernel_size / 2) * dilation\n",
    "        for i in range(self.nums):\n",
    "            convs.append(\n",
    "                nn.Conv1d(\n",
    "                    width,\n",
    "                    width,\n",
    "                    kernel_size=kernel_size,\n",
    "                    dilation=dilation,\n",
    "                    padding=num_pad,\n",
    "                )\n",
    "            )\n",
    "            bns.append(nn.BatchNorm1d(width))\n",
    "        self.convs = nn.ModuleList(convs)\n",
    "        self.bns = nn.ModuleList(bns)\n",
    "        self.conv3 = nn.Conv1d(width * scale, planes, kernel_size=1)\n",
    "        self.bn3 = nn.BatchNorm1d(planes)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.width = width\n",
    "        self.mp = nn.MaxPool1d(pool) if pool else False\n",
    "        self.afms = AFMS(planes)\n",
    "        if inplanes != planes:\n",
    "            self.residual = nn.Sequential(\n",
    "                nn.Conv1d(inplanes, planes, kernel_size=1, stride=1, bias=False)\n",
    "            )\n",
    "        else:\n",
    "            self.residual = nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = self.residual(x)\n",
    "        out = self.conv1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.bn1(out)\n",
    "        spx = torch.split(out, self.width, 1)\n",
    "        for i in range(self.nums):\n",
    "            if i == 0:\n",
    "                sp = spx[i]\n",
    "            else:\n",
    "                sp = sp + spx[i]\n",
    "            sp = self.convs[i](sp)\n",
    "            sp = self.relu(sp)\n",
    "            sp = self.bns[i](sp)\n",
    "            if i == 0:\n",
    "                out = sp\n",
    "            else:\n",
    "                out = torch.cat((out, sp), 1)\n",
    "        out = torch.cat((out, spx[self.nums]), 1)\n",
    "        out = self.conv3(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.bn3(out)\n",
    "        out += residual\n",
    "        if self.mp:\n",
    "            out = self.mp(out)\n",
    "        out = self.afms(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1551fde-835c-42a3-b1df-80bcb8691456",
   "metadata": {},
   "source": [
    "### RawNet3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b94c924-290a-4e90-9c36-826a994e995e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RawNet3.py\n",
    "class RawNet3(nn.Module):\n",
    "    def __init__(self, block, model_scale, context, summed, C=1024, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        nOut = kwargs[\"nOut\"]\n",
    "\n",
    "        self.context = context\n",
    "        self.encoder_type = kwargs[\"encoder_type\"]\n",
    "        self.log_sinc = kwargs[\"log_sinc\"]\n",
    "        self.norm_sinc = kwargs[\"norm_sinc\"]\n",
    "        self.out_bn = kwargs[\"out_bn\"]\n",
    "        self.summed = summed\n",
    "\n",
    "        self.preprocess = nn.Sequential(\n",
    "            PreEmphasis(), nn.InstanceNorm1d(1, eps=1e-4, affine=True)\n",
    "        )\n",
    "        self.conv1 = Encoder(\n",
    "            ParamSincFB(\n",
    "                C // 4,\n",
    "                251,\n",
    "                stride=kwargs[\"sinc_stride\"],\n",
    "            )\n",
    "        )\n",
    "        self.relu = nn.ReLU()\n",
    "        self.bn1 = nn.BatchNorm1d(C // 4)\n",
    "\n",
    "        self.layer1 = block(\n",
    "            C // 4, C, kernel_size=3, dilation=2, scale=model_scale, pool=5\n",
    "        )\n",
    "        self.layer2 = block(\n",
    "            C, C, kernel_size=3, dilation=3, scale=model_scale, pool=3\n",
    "        )\n",
    "        self.layer3 = block(C, C, kernel_size=3, dilation=4, scale=model_scale)\n",
    "        self.layer4 = nn.Conv1d(3 * C, 1536, kernel_size=1)\n",
    "\n",
    "        if self.context:\n",
    "            attn_input = 1536 * 3\n",
    "        else:\n",
    "            attn_input = 1536\n",
    "        print(\"self.encoder_type\", self.encoder_type)\n",
    "        if self.encoder_type == \"ECA\":\n",
    "            attn_output = 1536\n",
    "        elif self.encoder_type == \"ASP\":\n",
    "            attn_output = 1\n",
    "        else:\n",
    "            raise ValueError(\"Undefined encoder\")\n",
    "\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Conv1d(attn_input, 128, kernel_size=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Conv1d(128, attn_output, kernel_size=1),\n",
    "            nn.Softmax(dim=2),\n",
    "        )\n",
    "\n",
    "        self.bn5 = nn.BatchNorm1d(3072)\n",
    "\n",
    "        self.fc6 = nn.Linear(3072, nOut)\n",
    "        self.bn6 = nn.BatchNorm1d(nOut)\n",
    "\n",
    "        self.mp3 = nn.MaxPool1d(3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        :param x: input mini-batch (bs, samp)\n",
    "        \"\"\"\n",
    "\n",
    "        with torch.cuda.amp.autocast(enabled=False):\n",
    "            x = self.preprocess(x)\n",
    "            x = torch.abs(self.conv1(x))\n",
    "            if self.log_sinc:\n",
    "                x = torch.log(x + 1e-6)\n",
    "            if self.norm_sinc == \"mean\":\n",
    "                x = x - torch.mean(x, dim=-1, keepdim=True)\n",
    "            elif self.norm_sinc == \"mean_std\":\n",
    "                m = torch.mean(x, dim=-1, keepdim=True)\n",
    "                s = torch.std(x, dim=-1, keepdim=True)\n",
    "                s[s < 0.001] = 0.001\n",
    "                x = (x - m) / s\n",
    "\n",
    "        if self.summed:\n",
    "            x1 = self.layer1(x)\n",
    "            x2 = self.layer2(x1)\n",
    "            x3 = self.layer3(self.mp3(x1) + x2)\n",
    "        else:\n",
    "            x1 = self.layer1(x)\n",
    "            x2 = self.layer2(x1)\n",
    "            x3 = self.layer3(x2)\n",
    "\n",
    "        x = self.layer4(torch.cat((self.mp3(x1), x2, x3), dim=1))\n",
    "        x = self.relu(x)\n",
    "\n",
    "        t = x.size()[-1]\n",
    "\n",
    "        if self.context:\n",
    "            global_x = torch.cat(\n",
    "                (\n",
    "                    x,\n",
    "                    torch.mean(x, dim=2, keepdim=True).repeat(1, 1, t),\n",
    "                    torch.sqrt(\n",
    "                        torch.var(x, dim=2, keepdim=True).clamp(\n",
    "                            min=1e-4, max=1e4\n",
    "                        )\n",
    "                    ).repeat(1, 1, t),\n",
    "                ),\n",
    "                dim=1,\n",
    "            )\n",
    "        else:\n",
    "            global_x = x\n",
    "\n",
    "        w = self.attention(global_x)\n",
    "\n",
    "        mu = torch.sum(x * w, dim=2)\n",
    "        sg = torch.sqrt(\n",
    "            (torch.sum((x**2) * w, dim=2) - mu**2).clamp(min=1e-4, max=1e4)\n",
    "        )\n",
    "\n",
    "        x = torch.cat((mu, sg), 1)\n",
    "\n",
    "        x = self.bn5(x)\n",
    "\n",
    "        x = self.fc6(x)\n",
    "\n",
    "        if self.out_bn:\n",
    "            x = self.bn6(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "37b3bf27-a440-4f47-86c5-4b43b17f4967",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MainModel(**kwargs):\n",
    "\n",
    "    model = RawNet3(\n",
    "        Bottle2neck, model_scale=8, context=True, summed=True, **kwargs\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d41b3e-d648-4b35-9c0a-df872e1a34d0",
   "metadata": {},
   "source": [
    "#### Load pre-trained weights from the submodule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "32197ad0-4d32-4305-9baa-4369c79fbe9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.encoder_type ECA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fk/fbj1ksls7wq3z6dyxsdrrz9w0000gn/T/ipykernel_3200/3791338880.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"./models/model.pt\", map_location=lambda storage, loc: storage)[\"model\"])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RawNet3(\n",
       "  (preprocess): Sequential(\n",
       "    (0): PreEmphasis()\n",
       "    (1): InstanceNorm1d(1, eps=0.0001, momentum=0.1, affine=True, track_running_stats=False)\n",
       "  )\n",
       "  (conv1): Encoder(\n",
       "    (filterbank): ParamSincFB()\n",
       "  )\n",
       "  (relu): ReLU()\n",
       "  (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layer1): Bottle2neck(\n",
       "    (conv1): Conv1d(256, 1024, kernel_size=(1,), stride=(1,))\n",
       "    (bn1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (convs): ModuleList(\n",
       "      (0-6): 7 x Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "    )\n",
       "    (bns): ModuleList(\n",
       "      (0-6): 7 x BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv3): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))\n",
       "    (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "    (mp): MaxPool1d(kernel_size=5, stride=5, padding=0, dilation=1, ceil_mode=False)\n",
       "    (afms): AFMS(\n",
       "      (fc): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (sig): Sigmoid()\n",
       "    )\n",
       "    (residual): Sequential(\n",
       "      (0): Conv1d(256, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Bottle2neck(\n",
       "    (conv1): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))\n",
       "    (bn1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (convs): ModuleList(\n",
       "      (0-6): 7 x Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))\n",
       "    )\n",
       "    (bns): ModuleList(\n",
       "      (0-6): 7 x BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv3): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))\n",
       "    (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "    (mp): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "    (afms): AFMS(\n",
       "      (fc): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (sig): Sigmoid()\n",
       "    )\n",
       "    (residual): Identity()\n",
       "  )\n",
       "  (layer3): Bottle2neck(\n",
       "    (conv1): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))\n",
       "    (bn1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (convs): ModuleList(\n",
       "      (0-6): 7 x Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))\n",
       "    )\n",
       "    (bns): ModuleList(\n",
       "      (0-6): 7 x BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv3): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))\n",
       "    (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "    (afms): AFMS(\n",
       "      (fc): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (sig): Sigmoid()\n",
       "    )\n",
       "    (residual): Identity()\n",
       "  )\n",
       "  (layer4): Conv1d(3072, 1536, kernel_size=(1,), stride=(1,))\n",
       "  (attention): Sequential(\n",
       "    (0): Conv1d(4608, 128, kernel_size=(1,), stride=(1,))\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Conv1d(128, 1536, kernel_size=(1,), stride=(1,))\n",
       "    (4): Softmax(dim=2)\n",
       "  )\n",
       "  (bn5): BatchNorm1d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc6): Linear(in_features=3072, out_features=256, bias=True)\n",
       "  (bn6): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (mp3): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MainModel(nOut=256, encoder_type=\"ECA\", log_sinc=True, norm_sinc=\"mean\", out_bn=False, sinc_stride=10)\n",
    "model.load_state_dict(torch.load(\"./models/model.pt\", map_location=lambda storage, loc: storage)[\"model\"])\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3677d5-6db9-4160-b53b-fc983eee5414",
   "metadata": {},
   "source": [
    "#### Extract embeddings of audio file\n",
    "\n",
    "This function takes an audio file, splits it into segments, extracts the embeddings using the RawNet3 model, and returns the embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2303b368-077e-410e-8d00-360eb866dd83",
   "metadata": {},
   "source": [
    "An embedding in the context of RawNet3 is a compact and discriminative vector representation of an audio segment that captures the unique characteristics of the speaker, allowing for various speech processing and analysis tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3a7aa925-531f-4bf7-a2ac-0a3fe2cf9e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "\n",
    "def extract_speaker_embd(model, audio_file, n_samples=48000, n_segments=10, gpu=False):\n",
    "    audio, sample_rate = librosa.load(audio_file, sr=16000, mono=True)\n",
    "    \n",
    "    if len(audio) < n_samples:\n",
    "        shortage = n_samples - len(audio) + 1\n",
    "        audio = np.pad(audio, (0, shortage), \"wrap\")\n",
    "    \n",
    "    audios = []\n",
    "    startframe = np.linspace(0, len(audio) - n_samples, num=n_segments)\n",
    "    for asf in startframe:\n",
    "        audios.append(audio[int(asf):int(asf) + n_samples])\n",
    "    \n",
    "    audios = torch.from_numpy(np.stack(audios, axis=0).astype(np.float32))\n",
    "    if gpu:\n",
    "        audios = audios.to(\"cuda\")\n",
    "    with torch.no_grad():\n",
    "        output = model(audios)\n",
    "    \n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "88cf4eee-c25c-41c7-8cb9-bf1b228df335",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fk/fbj1ksls7wq3z6dyxsdrrz9w0000gn/T/ipykernel_3200/1709252647.py:69: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings shape: torch.Size([10, 256])\n"
     ]
    }
   ],
   "source": [
    "audio_file = \"./sample1.wav\"\n",
    "embeddings = extract_speaker_embd(model, audio_file, n_samples=48000, n_segments=10)\n",
    "print(\"Embeddings shape:\", embeddings.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
